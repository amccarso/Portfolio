{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Data-Oriented Computing, we have learned about a method of dividing objects into classes of similar objects whose nature is not well defined in advance. This method is K-means. In the handwritten character recognition problem, we know the character class of each image in the \"training\" data set, thus we should make use of that information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classifier method that we can use along with labelled training data, which requires little work beyond naming features, is the K-Nearest Neighbors algorithm. Simply put, we guess that a new example belongs to the same class as its nearest neighbors in a feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works as such: First, choose a number, k, of neighbors to be consulted. Then given a new image that we want to classify, we\n",
    "\n",
    "1) compute its feature vector\n",
    "\n",
    "2) find the classes of the k nearest neighbors of this feature among the training data\n",
    "\n",
    "3) use the mode of the classes of the nearest neighbors as your predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan on implementing a KDtree in order to store the points. These trees have been found to be very useful while conducting the K-Nearest Neighbors algorithm. As for the features to be used, I chose the amount of ink used, the left-right symmetry, the log aspect, and the disconnected components of black and white pixels in the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my new feature I decided to use the number of disconnected components in the array. In order to find this I flatten the array and count the number of moments in which the index is not the same value as the previous index. Thus the features I use will be: the amount of ink used to write the character, the height and width of the character, the symmetry, the number of disconnected components in the array, and the concavity of the character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I am not entirely sure of what is being asked from us or what I am supposed to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(pngs)\n",
    "#features = ['ink','log aspect','lr-asymmetry','right concavity']\n",
    "features = ['ink','log aspect','lr-asymmetry', 'disconnections', 'right concavity']\n",
    "d = len(features)\n",
    "F = np.empty((d,n))\n",
    "x = np.arange(0,w) # linspace(0,w,w,endpoint=False)\n",
    "y = np.arange(0,h) # linspace(0,h,h,endpoint=False)\n",
    "X,Y = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is where I create the feature vector. This includes exclusively the five features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,png in enumerate( pngs ):\n",
    "        #print(png)\n",
    "        img = Image.open(png)\n",
    "        #imshow(img)\n",
    "        a = np.array(img)\n",
    "        a = a[:,:,0]  # get just one layer- they are all the same\n",
    "        a = 255 - a   # invert so character is high values\n",
    "        ink  = a.sum() / (h*w*255)   # scaled to [0,1]  # maybe too extreme?  # better alternatives\n",
    "        if ink == 0:\n",
    "            print('Blank image:',png)\n",
    "            assert ink>0\n",
    "        F[0 ,k] = ink\n",
    "\n",
    "        # height and width of character\n",
    "        xmin = X[ a>0 ].min()\n",
    "        xmax = X[ a>0 ].max()\n",
    "        ymin = Y[ a>0 ].min()\n",
    "        ymax = Y[ a>0 ].max()\n",
    "        logaspect = np.log10((ymax-ymin)/(xmax-xmin))\n",
    "        F[1 ,k] = logaspect\n",
    "\n",
    "        # left-right asymmetry\n",
    "        cbbx = (xmin+xmax)/2   # center of bounding box\n",
    "        cogx = (X*a).sum() / a.sum() # x-coordinate of center of mass of ink\n",
    "        lrasymmetry = (cogx-cbbx) / (xmax-xmin)\n",
    "        F[2 ,k] = lrasymmetry\n",
    "        \n",
    "        #disconnections        \n",
    "        flat = np.ravel(a)\n",
    "        disconnections = 0\n",
    "        for i in range(len(flat)-1):\n",
    "            if flat[i] != flat[i+1] and i < len(flat):\n",
    "                disconnections += 1\n",
    "        F[3,k] = disconnections\n",
    "        \n",
    "        # right concavity\n",
    "        xstar = w - np.argmax( np.fliplr(a) > 0, axis=1 ).max()\n",
    "        F[4, k] = (xmax-xstar)/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charclass(png):     # extract character class name from file name\n",
    "        return png.split('__')[1][:-4]\n",
    "\n",
    "allpngs = sorted( glob('pngs/*.png') )\n",
    "h,w,_ = np.array(Image.open(allpngs[0])).shape\n",
    "h,w\n",
    "selection = sorted({charclass(png) for png in allpngs}) # ['8','9','minus'] # \n",
    "\n",
    "pngs = [png for png in allpngs if charclass(png) in selection]\n",
    "\n",
    "# Load flattened images as columns of big array X\n",
    "X = np.empty((h*w,len(pngs)))\n",
    "for i,png in enumerate(pngs):\n",
    "    X[:,i] = 255 - np.array(Image.open(png))[:,:,0].reshape(h*w)\n",
    "# Get the true class numbers of all the images\n",
    "y = [selection.index(charclass(png)) for png in pngs]  # true classes of images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "X is the pixel array of the data\n",
    "\n",
    "y is the array of each images class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT = F.T\n",
    "#let's begin by rescaling the data to lie in the unit square\n",
    "FT -= FT.min(axis=0)\n",
    "FT /= FT.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(FT, k, y):\n",
    "    n = FT.shape[0]\n",
    "    KDtree = spatial.KDTree(FT, FT.shape[1])\n",
    "    classes = []\n",
    "    index = 0\n",
    "    for point in FT:\n",
    "        #print(KDtree.query(point, k=k)[1])\n",
    "        index += 1\n",
    "        modes = []\n",
    "        for neighbor in KDtree.query(point, k=k)[1]:\n",
    "            modes.append(y[neighbor])\n",
    "            #print(y[neighbor])\n",
    "        classes.append((index, int(stats.mode(modes)[0])))\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now have the nearest neighbors. want to put neighbors into a class with each other to find class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (2, 5),\n",
       " (3, 4),\n",
       " (4, 0),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 0),\n",
       " (8, 2),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 2),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 2),\n",
       " (20, 2),\n",
       " (21, 0),\n",
       " (22, 2),\n",
       " (23, 2),\n",
       " (24, 2),\n",
       " (25, 2),\n",
       " (26, 2),\n",
       " (27, 2),\n",
       " (28, 2),\n",
       " (29, 2),\n",
       " (30, 3)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN(FT, 4, y)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.78% for 2 neighbors\n",
      "Accuracy is 0.77% for 3 neighbors\n",
      "Accuracy is 0.75% for 4 neighbors\n",
      "Accuracy is 0.75% for 5 neighbors\n",
      "Accuracy is 0.75% for 6 neighbors\n",
      "Accuracy is 0.75% for 7 neighbors\n",
      "Accuracy is 0.74% for 8 neighbors\n",
      "Accuracy is 0.74% for 9 neighbors\n",
      "Accuracy is 0.73% for 10 neighbors\n",
      "Accuracy is 0.73% for 11 neighbors\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "percents = []\n",
    "for k in range(2,12):\n",
    "    classes.append(kNN(FT, k, y))\n",
    "    percent = 0\n",
    "    for index, _class in classes[k-2]:\n",
    "        try:\n",
    "            if _class == y[index]:\n",
    "                percent += 1\n",
    "        except IndexError:\n",
    "            break\n",
    "    percent = round(percent/len(y),2)\n",
    "    percents.append(percent)\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    print('Accuracy is ' + str(percents[i]) + '% for {k} neighbors'.format(k=i+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy seems to decrease with the number of neighbors, however there was an instance of experimentation in which the highest accuracy was not found in the iteration with the lowest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With less features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ink', 'disconnections', 'lr-asymmetry']\n",
    "d = len(features)\n",
    "F = np.empty((d,n))\n",
    "x = np.arange(0,w) # linspace(0,w,w,endpoint=False)\n",
    "y = np.arange(0,h) # linspace(0,h,h,endpoint=False)\n",
    "X,Y = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I decrease the number of features in order to determine how much the features used influence the accuracy of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,png in enumerate( pngs ):\n",
    "        #print(png)\n",
    "        img = Image.open(png)\n",
    "        #imshow(img)\n",
    "        a = np.array(img)\n",
    "        a = a[:,:,0]  # get just one layer- they are all the same\n",
    "        a = 255 - a   # invert so character is high values\n",
    "        ink  = a.sum() / (h*w*255)   # scaled to [0,1]  # maybe too extreme?  # better alternatives\n",
    "        if ink == 0:\n",
    "            print('Blank image:',png)\n",
    "            assert ink>0\n",
    "        F[0 ,k] = ink\n",
    "\n",
    "        # height and width of character\n",
    "        #xmin = X[ a>0 ].min()\n",
    "        #xmax = X[ a>0 ].max()\n",
    "        #ymin = Y[ a>0 ].min()\n",
    "        #ymax = Y[ a>0 ].max()\n",
    "        #logaspect = np.log10((ymax-ymin)/(xmax-xmin))\n",
    "        #F[1 ,k] = logaspect\n",
    "        \n",
    "        #disconnections        \n",
    "        flat = np.ravel(a)\n",
    "        disconnections = 0\n",
    "        for i in range(len(flat)-1):\n",
    "            if flat[i] != flat[i+1] and i < len(flat):\n",
    "                disconnections += 1\n",
    "        F[1,k] = disconnections\n",
    "        \n",
    "        # left-right asymmetry\n",
    "        cbbx = (xmin+xmax)/2   # center of bounding box\n",
    "        cogx = (X*a).sum() / a.sum() # x-coordinate of center of mass of ink\n",
    "        lrasymmetry = (cogx-cbbx) / (xmax-xmin)\n",
    "        F[2 ,k] = lrasymmetry\n",
    "        \n",
    "        # right concavity\n",
    "        #xstar = w - np.argmax( np.fliplr(a) > 0, axis=1 ).max()\n",
    "        #F[4, k] = (xmax-xstar)/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpngs = sorted( glob('pngs/*.png') )\n",
    "h,w,_ = np.array(Image.open(allpngs[0])).shape\n",
    "h,w\n",
    "selection = sorted({charclass(png) for png in allpngs}) # ['8','9','minus'] # \n",
    "\n",
    "pngs = [png for png in allpngs if charclass(png) in selection]\n",
    "\n",
    "# Load flattened images as columns of big array X\n",
    "X = np.empty((h*w,len(pngs)))\n",
    "for i,png in enumerate(pngs):\n",
    "    X[:,i] = 255 - np.array(Image.open(png))[:,:,0].reshape(h*w)\n",
    "# Get the true class numbers of all the images\n",
    "y = [selection.index(charclass(png)) for png in pngs]  # true classes of images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT = F.T\n",
    "#let's begin by rescaling the data to lie in the unit square\n",
    "FT -= FT.min(axis=0)\n",
    "FT /= FT.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7% for 2 neighbors\n",
      "Accuracy is 0.71% for 3 neighbors\n",
      "Accuracy is 0.68% for 4 neighbors\n",
      "Accuracy is 0.68% for 5 neighbors\n",
      "Accuracy is 0.67% for 6 neighbors\n",
      "Accuracy is 0.66% for 7 neighbors\n",
      "Accuracy is 0.66% for 8 neighbors\n",
      "Accuracy is 0.66% for 9 neighbors\n",
      "Accuracy is 0.65% for 10 neighbors\n",
      "Accuracy is 0.65% for 11 neighbors\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "percents = []\n",
    "for k in range(2,12):\n",
    "    classes.append(kNN(FT, k, y))\n",
    "    percent = 0\n",
    "    for index, _class in classes[k-2]:\n",
    "        try:\n",
    "            if _class == y[index]:\n",
    "                percent += 1\n",
    "        except IndexError:\n",
    "            break\n",
    "    percent = round(percent/len(y),2)\n",
    "    percents.append(percent)\n",
    "    \n",
    "    \n",
    "for i in range(10):\n",
    "    print('Accuracy is ' + str(percents[i]) + '% for {k} neighbors'.format(k=i+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using less features leads to a decrease in criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the KDTree keeps track of the nearest neighbors in it's structure. This left for me to simply find the classes of the neighbors to determine the class of the point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I have found is that more neighbors does not always lead to more accurate results, but there is in fact, however, a decrease in accuracy with more neighbors. The accuracy seems to converge to some point with k being higher. I have found that increasing the number of features can increase the accuracy of the kNN algorithm. As well, I found that the accuracy depends on the strength of the features used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My classifier does not perform as well as the Neural Network that we devised in class, or as well as the K-means algorithm that we implemented. I believe there is a correlation between the ease of implementation and accuracy for kNN. This is because K-means was more accurate and more difficult to implement. I am also aware that Neural Networks were created in order to provide an instrument that was incredibly accurate in performing tasks. kNN seems to be the least accurate of the methods for the handwritten character methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
